from flask import Flask, request, jsonify
from flask_cors import CORS
import json
import re
from threading import Lock
import requests
import hashlib
import os
import sys
import time
from datetime import datetime, timedelta
from collections import defaultdict

app = Flask(__name__)
# ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ CORS Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø§Ø¯Ù† Ø¨Ù‡ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø§Ø² Ø§ÙØ²ÙˆÙ†Ù‡ Ú©Ø±ÙˆÙ…
CORS(app)

FORBIDDEN_HOSTS = ["melliun.org", "nejatngo.org", "dw.com", "hammihanonline.ir"]
keyword_lock = Lock()
image_hash_lock = Lock()

# ğŸš¨ Ø´Ø¨ÛŒÙ‡ Ø³Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³: Ø§ÛŒÙ† Ù…ØªØºÛŒØ±Ù‡Ø§ Ù¾Ø³ Ø§Ø² Ù‡Ø± Ø¨Ø§Ø± Ø®Ø§Ù…ÙˆØ´ Ø´Ø¯Ù† Ø³Ø±ÙˆØ± (Cold Start) Ø±ÛŒØ³Øª Ù…ÛŒ Ø´ÙˆÙ†Ø¯.
CONTENT_HISTORY = {}
CONTENT_HISTORY_LOCK = Lock()

# ğŸš¨ ÙÙ‡Ø±Ø³Øª Ø¬Ø¯ÛŒØ¯: ÙÙ‡Ø±Ø³Øª Ù‡ÙØ´â€ŒÙ‡Ø§ÛŒ ØªØµØ§ÙˆÛŒØ± Ù…Ù…Ù†ÙˆØ¹Ù‡ (SHA256) Ú©Ù‡ Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.
# Ø¯Ø± Ù…Ø­ÛŒØ· ÙˆØ§Ù‚Ø¹ÛŒØŒ Ø§ÛŒÙ†Ù‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¯Ø± ÛŒÚ© Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¯Ø§Ø¦Ù…ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´ÙˆÙ†Ø¯.
FORBIDDEN_IMAGE_HASHES = set()

# ğŸš¨ Ø³ÛŒØ³ØªÙ… Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ: Ø°Ø®ÛŒØ±Ù‡ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ IP
USER_LOGS = defaultdict(list)
USER_LOGS_LOCK = Lock()
# Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±
MAX_LOGS_PER_USER = 1000
# Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ (Ø±ÙˆØ²)
LOG_RETENTION_DAYS = 30

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù‡Ø¯Ø± Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯Ù† ØªÙˆØ³Ø· Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ Ø¹Ú©Ø³
REQUEST_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (compatible; Content-Guard-Bot/1.0;)'
}
# Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù‡Ø± Ø¹Ú©Ø³
DOWNLOAD_TIMEOUT = 3

# ØªØ¹Ø±ÛŒÙ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ú©Ù„Ù…Ø§Øª Ù…Ù…Ù†ÙˆØ¹Ù‡ (Ú©Ù„Ù…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡) - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù‚ÙˆÛŒ Regex Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù…Ø±Ø² Ú©Ù„Ù…Ù‡
SENSITIVE_KEYWORDS = {
    r'(?:\s|^)Ø´ÙˆØ±Ø´', r'(?:\s|^)ØªØ­Ø±ÛŒÙ…', r'(?:\s|^)Ø¨Ø­Ø±Ø§Ù†', r'(?:\s|^)Ø³Ù‚ÙˆØ·',
    r'(?:\s|^)Ø¶Ø¯Ù†Ø¸Ø§Ù…', r'(?:\s|^)Ø§Ø¹ØªØ±Ø§Ø¶', r'(?:\s|^)Ø¨Ø±Ø§Ù†Ø¯Ø§Ø²',
    r'(?:\s|^)Ù‚ÛŒØ§Ù…', r'(?:\s|^)Ø¢Ø²Ø§Ø¯ÛŒ', r'(?:\s|^)Ø±Ù‡Ø¨Ø±', r'(?:\s|^)Ø®Ø§Ù…Ù†Ù‡â€ŒØ§ÛŒ',
    r'(?:\s|^)Ø§Ù†Ù‚Ù„Ø§Ø¨', r'(?:\s|^)Ø³Ù¾Ø§Ù‡', r'(?:\s|^)Ø¨Ø³ÛŒØ¬', r'(?:\s|^)Ú¯Ø´Øª\sØ§Ø±Ø´Ø§Ø¯',
    r'(?:\s|^)Ø³Ø±Ú©ÙˆØ¨', r'(?:\s|^)ÙØªÙ†Ù‡', r'(?:\s|^)Ø±Ú˜ÛŒÙ…', r'(?:\s|^)Ø¬Ù…Ù‡ÙˆØ±ÛŒ',
    r'(?:\s|^)Ø§Ø¹Ø¯Ø§Ù…', r'(?:\s|^)Ù†Ø¸Ø§Ù…', r'(?:\s|^)ÙˆÙ„Ø§ÛŒØª\sÙÙ‚ÛŒÙ‡', r'(?:\s|^)Ù…Ù„Ø§',
    r'(?:\s|^)Ù‚ÙˆÙ‡\sÙ‚Ø¶Ø§ÛŒÛŒÙ‡', r'(?:\s|^)Ø²Ù†Ø¯Ø§Ù†ÛŒ\sØ³ÛŒØ§Ø³ÛŒ', r'(?:\s|^)Ø¯ÛŒÚ©ØªØ§ØªÙˆØ±'
}


def get_client_ip():
    """Ø¯Ø±ÛŒØ§ÙØª IP Ú©Ø§Ø±Ø¨Ø± Ø§Ø² Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª"""
    if request.headers.get('X-Forwarded-For'):
        return request.headers.get('X-Forwarded-For').split(',')[0]
    elif request.headers.get('X-Real-IP'):
        return request.headers.get('X-Real-IP')
    return request.remote_addr


def log_user_activity(ip_address, activity_type, details):
    """Ø°Ø®ÛŒØ±Ù‡ ÙØ¹Ø§Ù„ÛŒØª Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± Ø³ÛŒØ³ØªÙ… Ù„Ø§Ú¯"""
    with USER_LOGS_LOCK:
        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
        current_time = time.time()
        if ip_address in USER_LOGS:
            USER_LOGS[ip_address] = [
                log for log in USER_LOGS[ip_address]
                if current_time - log['timestamp'] <= LOG_RETENTION_DAYS * 86400
            ]

        # Ø§ÛŒØ¬Ø§Ø¯ Ù„Ø§Ú¯ Ø¬Ø¯ÛŒØ¯
        log_entry = {
            'timestamp': current_time,
            'datetime': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'activity_type': activity_type,
            'details': details,
            'user_agent': request.headers.get('User-Agent', 'Unknown'),
            'url': request.url if request.method == 'GET' else None
        }

        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù„Ø§Ú¯ Ø¬Ø¯ÛŒØ¯
        USER_LOGS[ip_address].append(log_entry)

        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØ¹Ø¯Ø§Ø¯ Ù„Ø§Ú¯â€ŒÙ‡Ø§
        if len(USER_LOGS[ip_address]) > MAX_LOGS_PER_USER:
            USER_LOGS[ip_address] = USER_LOGS[ip_address][-MAX_LOGS_PER_USER:]

        return log_entry


def cleanup_old_logs():
    """Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ"""
    with USER_LOGS_LOCK:
        current_time = time.time()
        cutoff_time = current_time - (LOG_RETENTION_DAYS * 86400)

        for ip in list(USER_LOGS.keys()):
            USER_LOGS[ip] = [
                log for log in USER_LOGS[ip]
                if log['timestamp'] > cutoff_time
            ]
            if not USER_LOGS[ip]:
                del USER_LOGS[ip]


def get_image_hash(url):
    """
    ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø´ SHA256 Ø¢Ù†.
    Ø§Ú¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ² Ù†Ø¨ÙˆØ¯ØŒ None Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    try:
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† URLÙ‡Ø§ÛŒ ØºÛŒØ±Ù…Ø¹ØªØ¨Ø±
        if not url.startswith('http'):
            return None

            # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø­ØªÙˆØ§ÛŒ ØªØµÙˆÛŒØ± Ø¨Ø§ Ø§Ø³ØªØ±ÛŒÙ… Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø²Ù…Ø§Ù†ÛŒ
        response = requests.get(url, headers=REQUEST_HEADERS, timeout=DOWNLOAD_TIMEOUT, stream=True)
        response.raise_for_status()  # Ø®Ø·Ø§Ù‡Ø§ÛŒ HTTP Ø±Ø§ Ù¾Ø±ØªØ§Ø¨ Ù…ÛŒ Ú©Ù†Ø¯

        # ÙÙ‚Ø· ØªØµØ§ÙˆÛŒØ± Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù† (Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø¨Ø§Ø±)
        content_type = response.headers.get('Content-Type', '')
        if 'image' not in content_type:
            return None

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø´ SHA256
        sha256_hash = hashlib.sha256()
        for chunk in response.iter_content(chunk_size=4096):
            sha256_hash.update(chunk)

        return sha256_hash.hexdigest()

    except requests.exceptions.RequestException:
        # Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ØŒ Timeout ÛŒØ§ Ø³Ø§ÛŒØ± Ù…Ø´Ú©Ù„Ø§Øª Ø¯Ø§Ù†Ù„ÙˆØ¯
        return None
    except Exception:
        # Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡
        return None


def normalize_text(text):
    """
    Ù…ØªÙ† Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‚Øª ÙÛŒÙ„ØªØ±ÛŒÙ†Ú¯ Ø¹Ø§Ø¯ÛŒâ€ŒØ³Ø§Ø²ÛŒ (Ù†Ø±Ù…Ø§Ù„Ø§ÛŒØ²) Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (Ù…Ø«Ù„Ø§Ù‹ ØªØ¨Ø¯ÛŒÙ„ ÛŒ Ø¹Ø±Ø¨ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ).
    """
    text = str(text).lower()
    text = text.replace('ÙŠ', 'ÛŒ').replace('Ùƒ', 'Ú©')
    # Ø­Ø°Ù Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ± Ø¯Ø± Regex
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text


def check_keyword_robust(article_text):
    """
    Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‚ÙˆÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Regex Ù¾Ø³ Ø§Ø² Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ.
    """
    normalized_text = normalize_text(article_text)

    with keyword_lock:
        for pattern in SENSITIVE_KEYWORDS:
            if re.search(pattern, normalized_text):
                return True
    return False


def simulate_learning(content_data):
    """
    Ø´Ø¨ÛŒÙ‡ Ø³Ø§Ø²ÛŒ Ù…Ú©Ø§Ù†ÛŒØ³Ù… ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±: Ø§Ú¯Ø± Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ø¯ÛŒØ¯ÛŒ Ø§Ø² Ù…Ù†Ø¨Ø¹ Ù…Ù…Ù†ÙˆØ¹Ù‡ Ù¾ÛŒØ¯Ø§ Ø´ÙˆØ¯ØŒ
    Ú©Ù„Ù…Ø§Øª Ùˆ Ù‡ÙØ´â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ù„ÛŒØ³Øª ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒ Ú©Ù†Ø¯.
    """
    article_text = content_data.get('text', '')
    image_sources = content_data.get('imageSources', [])

    # 1. ØªØ´Ø®ÛŒØµ Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‡Ø´ (Ø¨Ø±Ø§ÛŒ Ø´Ø¨ÛŒÙ‡ Ø³Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³)
    normalized_text = normalize_text(article_text)
    # Ù‡Ø´ Ú©Ø±Ø¯Ù† 500 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø¨Ø§Ø±
    content_hash = hashlib.md5(normalized_text[:500].encode('utf-8')).hexdigest()

    with CONTENT_HISTORY_LOCK:
        if content_hash in CONTENT_HISTORY:
            # Ù…Ø­ØªÙˆØ§ ØªÚ©Ø±Ø§Ø±ÛŒ Ø§Ø³ØªØŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.
            return 0, 0
        CONTENT_HISTORY[content_hash] = True

    # --- ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ ---
    # ÛŒØ§ÙØªÙ† Ú©Ù„Ù…Ø§Øª ÙØ§Ø±Ø³ÛŒ/Ø¹Ø±Ø¨ÛŒ Ø¨Ø§ Ø·ÙˆÙ„ 4 Ú©Ø§Ø±Ø§Ú©ØªØ± ÛŒØ§ Ø¨ÛŒØ´ØªØ±
    all_words = set(re.findall(r'[\u0600-\u06FF\u0750-\u077F]{4,}', normalized_text))
    newly_added_keywords = 0
    with keyword_lock:
        for word in all_words:
            safe_term = r'(?:\s|^)' + re.escape(word)  # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù…Ø±Ø² Ú©Ù„Ù…Ù‡
            if safe_term not in SENSITIVE_KEYWORDS:
                SENSITIVE_KEYWORDS.add(safe_term)
                newly_added_keywords += 1

    # --- ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù‡ÙØ´â€ŒÙ‡Ø§ÛŒ ØªØµØ§ÙˆÛŒØ± ---
    newly_added_hashes = 0
    with image_hash_lock:
        for src in image_sources:
            # ÙÙ‚Ø· URLÙ‡Ø§ÛŒÛŒ Ø±Ø§ ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ± Ú©Ù‡ Ø§Ø² ÛŒÚ©ÛŒ Ø§Ø² FORBIDDEN_HOSTS Ù…ÛŒ Ø¢ÛŒÙ†Ø¯
            if any(host in src for host in FORBIDDEN_HOSTS):  # ğŸš¨ ØªØºÛŒÛŒØ± Ø§ÛŒÙ† Ø®Ø·
                img_hash = get_image_hash(src)
                if img_hash and img_hash not in FORBIDDEN_IMAGE_HASHES:
                    FORBIDDEN_IMAGE_HASHES.add(img_hash)
                    newly_added_hashes += 1

    return newly_added_keywords, newly_added_hashes


def check_nested_api_logic(content_data, ip_address=None):
    """
    Ø§Ø¬Ø±Ø§ÛŒ Ù…Ù†Ø·Ù‚ API ØªÙˆØ¯Ø±ØªÙˆÛŒ Ú†Ù†Ø¯Ù„Ø§ÛŒÙ‡ Ø¨Ø§ Ù…Ù†Ø·Ù‚ ÙÛŒÙ„ØªØ±ÛŒÙ†Ú¯ ØªÙ‚ÙˆÛŒØª Ø´Ø¯Ù‡ Ùˆ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±.
    """
    article_text = content_data.get('text', '')
    links_to_check = content_data.get('links', [])
    image_sources = content_data.get('imageSources', [])

    # 0. Ø¨Ø±Ø±Ø³ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
    has_forbidden_source = any(any(host in src for host in FORBIDDEN_HOSTS) for src in image_sources) or any(
        any(host in link for host in FORBIDDEN_HOSTS) for link in links_to_check)

    if has_forbidden_source:
        new_k, new_i = simulate_learning(content_data)
        if new_k > 0 or new_i > 0:
            print(f"AUTOMATIC LEARNING: Added {new_k} new keywords and {new_i} new image hashes.")
    # --- Ù¾Ø§ÛŒØ§Ù† Ù…Ú©Ø§Ù†ÛŒØ²Ù… ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ---

    # 1. Ø¨Ø±Ø±Ø³ÛŒ Ù‡ÙØ´ ØªØµØ§ÙˆÛŒØ±: Ø¢ÛŒØ§ ØªØµÙˆÛŒØ± ÙØ¹Ù„ÛŒØŒ Ù‡ÙØ´ Ù…Ù…Ù†ÙˆØ¹Ù‡ Ø¯Ø§Ø±Ø¯ØŸ (Ù‚ÙˆÛŒâ€ŒØªØ±ÛŒÙ† ÙÛŒÙ„ØªØ± Ø¬Ø¯ÛŒØ¯)
    with image_hash_lock:
        for src in image_sources:
            current_hash = get_image_hash(src)
            if current_hash and current_hash in FORBIDDEN_IMAGE_HASHES:
                # Ø«Ø¨Øª Ù„Ø§Ú¯
                if ip_address:
                    log_user_activity(ip_address, 'FILTER_HARD', {
                        'action': 'FILTER_HARD',
                        'reason': 'HIGH_PRIORITY: Known Forbidden Image Hash Detected',
                        'image_url': src[:100],
                        'content_preview': article_text[:200]
                    })
                return {
                    "action": "FILTER_HARD",
                    "reason": "HIGH_PRIORITY: Known Forbidden Image Hash Detected"
                }

    # 2. Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ù…Ù†Ø¨Ø¹ Ù…Ù…Ù†ÙˆØ¹Ù‡ (Ø¨Ø±Ø§ÛŒ ØªØµÙˆÛŒØ± ÛŒØ§ Ù„ÛŒÙ†Ú©) - Ø§ÛŒÙ† ÛŒÚ© ÙÛŒÙ„ØªØ± Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø³Ø±ÛŒØ¹ Ø§Ø³Øª.
    if any(any(host in src for host in FORBIDDEN_HOSTS) for src in image_sources):
        # Ø«Ø¨Øª Ù„Ø§Ú¯
        if ip_address:
            log_user_activity(ip_address, 'FILTER_HARD', {
                'action': 'FILTER_HARD',
                'reason': 'HIGH_PRIORITY: Image Source from Forbidden Host Detected (URL Match)',
                'forbidden_hosts': FORBIDDEN_HOSTS,
                'content_preview': article_text[:200]
            })
        return {
            "action": "FILTER_HARD",
            "reason": "HIGH_PRIORITY: Image Source from Forbidden Host Detected (URL Match)"
        }

    # 3. Ù…Ù†Ø·Ù‚ Ù„ÛŒÙ†Ú© Ùˆ Ù…ØªÙ†
    has_forbidden_link = any(any(host in link for host in FORBIDDEN_HOSTS) for link in links_to_check)

    if has_forbidden_link:
        if len(article_text) > 100 and check_keyword_robust(article_text):
            # Ø«Ø¨Øª Ù„Ø§Ú¯
            if ip_address:
                log_user_activity(ip_address, 'FILTER_HARD', {
                    'action': 'FILTER_HARD',
                    'reason': 'Nested Logic: Forbidden Link + Sensitive Topic Match (Robust)',
                    'forbidden_links': [link[:100] for link in links_to_check if
                                        any(host in link for host in FORBIDDEN_HOSTS)],
                    'content_preview': article_text[:200]
                })
            return {
                "action": "FILTER_HARD",
                "reason": "Nested Logic: Forbidden Link + Sensitive Topic Match (Robust)"
            }
        # Ø§Ú¯Ø± Ù„ÛŒÙ†Ú© Ù…Ù…Ù†ÙˆØ¹Ù‡ Ø¨ÙˆØ¯ Ø§Ù…Ø§ Ù…ÙˆØ¶ÙˆØ¹ Ø­Ø³Ø§Ø³ Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ø§Ø² Ù‡Ù… Ø³Ø®Øª Ù…Ø³Ø¯ÙˆØ¯ Ú©Ù† (Ø§Ø­ØªÛŒØ§Ø· Ø¨ÛŒØ´ØªØ±)
        # Ø«Ø¨Øª Ù„Ø§Ú¯
        if ip_address:
            log_user_activity(ip_address, 'FILTER_HARD', {
                'action': 'FILTER_HARD',
                'reason': 'HIGH_PRIORITY: Forbidden Link Detected',
                'forbidden_links': [link[:100] for link in links_to_check if
                                    any(host in link for host in FORBIDDEN_HOSTS)]
            })
        return {
            "action": "FILTER_HARD",
            "reason": "HIGH_PRIORITY: Forbidden Link Detected"
        }

    # 4. ÙÛŒÙ„ØªØ±ÛŒÙ†Ú¯ Ø³Ø¨Ú©â€ŒØªØ± (Ø¨Ø±Ø±Ø³ÛŒ ÙÙ‚Ø· Ù…ØªÙ†)
    if check_keyword_robust(article_text):
        # Ø«Ø¨Øª Ù„Ø§Ú¯
        if ip_address:
            log_user_activity(ip_address, 'FILTER_LIGHT', {
                'action': 'FILTER_LIGHT',
                'reason': 'Generic Sensitive Topic Found (Robust)',
                'content_preview': article_text[:200]
            })
        return {"action": "FILTER_LIGHT", "reason": "Generic Sensitive Topic Found (Robust)"}

    # Ø«Ø¨Øª Ù„Ø§Ú¯ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Ù…Ø¬Ø§Ø²
    if ip_address:
        log_user_activity(ip_address, 'ALLOW', {
            'action': 'ALLOW',
            'reason': 'Content is clear.',
            'content_preview': article_text[:100]
        })
    return {"action": "ALLOW", "reason": "Content is clear."}


# Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³Ø±ÙˆØ±
@app.route('/', methods=['GET'])
def home():
    # Ù†Ù…Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ùˆ ØªØµØ§ÙˆÛŒØ± ÙÛŒÙ„ØªØ± Ø¨Ø±Ø§ÛŒ ØªØ£ÛŒÛŒØ¯ ØµØ­Øª ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
    total_images = 0
    with image_hash_lock:
        total_images = len(FORBIDDEN_IMAGE_HASHES)

    # ØªØ¹Ø¯Ø§Ø¯ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
    with USER_LOGS_LOCK:
        total_logs = sum(len(logs) for logs in USER_LOGS.values())
        unique_users = len(USER_LOGS)

    return f"""
    <html>
        <head><title>Iran Blocker API</title></head>
        <body>
            <h1>Python Content Filter API is running!</h1>
            <ul>
                <li>Total keywords: {len(SENSITIVE_KEYWORDS)}</li>
                <li>Total forbidden image hashes: {total_images}</li>
                <li>Total users logged: {unique_users}</li>
                <li>Total logs stored: {total_logs}</li>
            </ul>
            <p>API Endpoints:</p>
            <ul>
                <li><a href="/analyze_content_api">/analyze_content_api</a> (POST)</li>
                <li><a href="/get_user_logs">/get_user_logs</a> (GET)</li>
                <li><a href="/get_system_stats">/get_system_stats</a> (GET)</li>
            </ul>
        </body>
    </html>
    """, 200


@app.route('/analyze_content_api', methods=['POST'])
def analyze_content_api():
    """
    Ù†Ù‚Ø·Ù‡ Ù¾Ø§ÛŒØ§Ù†ÛŒ Ú©Ù‡ Ø§ÙØ²ÙˆÙ†Ù‡ Ú©Ø±ÙˆÙ… Ø¢Ù† Ø±Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙˆÚ©Ù† Ù†Ø¯Ø§Ø±Ø¯).
    """
    ip_address = get_client_ip()
    data = request.get_json()

    if not data or 'content' not in data:
        # Ø«Ø¨Øª Ù„Ø§Ú¯ Ø®Ø·Ø§
        log_user_activity(ip_address, 'ERROR', {
            'error': 'No content provided',
            'request_data': str(data)[:500]
        })
        return jsonify({"error": "No content provided."}), 400

    result = check_nested_api_logic(data['content'], ip_address)

    # Ø«Ø¨Øª Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„
    log_user_activity(ip_address, 'ANALYSIS_RESULT', {
        'result': result,
        'content_length': len(data['content'].get('text', '')) if data.get('content') else 0,
        'links_count': len(data['content'].get('links', [])) if data.get('content') else 0,
        'images_count': len(data['content'].get('imageSources', [])) if data.get('content') else 0
    })

    return jsonify(result)


@app.route('/get_user_logs', methods=['GET'])
def get_user_logs():
    """
    Ø¯Ø±ÛŒØ§ÙØª Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ IP
    """
    ip_address = get_client_ip()
    limit = request.args.get('limit', default=50, type=int)
    activity_type = request.args.get('type', default=None, type=str)

    with USER_LOGS_LOCK:
        user_logs = USER_LOGS.get(ip_address, [])

        # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ ÙØ¹Ø§Ù„ÛŒØª
        if activity_type:
            user_logs = [log for log in user_logs if log['activity_type'] == activity_type]

        # Ù…Ø±ØªØ¨ Ø³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù† (Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ø§ÙˆÙ„)
        user_logs.sort(key=lambda x: x['timestamp'], reverse=True)

        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØ¹Ø¯Ø§Ø¯
        user_logs = user_logs[:limit]

    return jsonify({
        'user_ip': ip_address,
        'total_logs': len(USER_LOGS.get(ip_address, [])),
        'filtered_logs': len(user_logs),
        'logs': user_logs
    })


@app.route('/clear_user_logs', methods=['POST'])
def clear_user_logs():
    """
    Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±
    """
    ip_address = get_client_ip()

    with USER_LOGS_LOCK:
        if ip_address in USER_LOGS:
            deleted_count = len(USER_LOGS[ip_address])
            del USER_LOGS[ip_address]
            return jsonify({
                'success': True,
                'message': f'Deleted {deleted_count} logs for user {ip_address}',
                'deleted_count': deleted_count
            })
        else:
            return jsonify({
                'success': False,
                'message': f'No logs found for user {ip_address}'
            }), 404


@app.route('/get_system_stats', methods=['GET'])
def get_system_stats():
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø³ÛŒØ³ØªÙ…
    """
    with USER_LOGS_LOCK:
        total_users = len(USER_LOGS)
        total_logs = sum(len(logs) for logs in USER_LOGS.values())

        # Ø¢Ù…Ø§Ø± ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§
        activity_stats = {}
        for logs in USER_LOGS.values():
            for log in logs:
                activity_type = log['activity_type']
                activity_stats[activity_type] = activity_stats.get(activity_type, 0) + 1

    with image_hash_lock:
        total_image_hashes = len(FORBIDDEN_IMAGE_HASHES)

    with keyword_lock:
        total_keywords = len(SENSITIVE_KEYWORDS)

    return jsonify({
        'system_stats': {
            'total_users': total_users,
            'total_logs': total_logs,
            'total_image_hashes': total_image_hashes,
            'total_keywords': total_keywords,
            'forbidden_hosts': FORBIDDEN_HOSTS,
            'log_retention_days': LOG_RETENTION_DAYS,
            'max_logs_per_user': MAX_LOGS_PER_USER
        },
        'activity_stats': activity_stats,
        'timestamp': time.time(),
        'datetime': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    })


# Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
if __name__ == '__main__':
    # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Ø¯Ø± Ø´Ø±ÙˆØ¹
    cleanup_old_logs()

    # Ø§ÛŒÙ† Ø®Ø· ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø­Ù„ÛŒ Ø§Ø³Øª.
    # Ø¯Ø± Ù…Ø­ÛŒØ· Ø§Ø¨Ø±ÛŒ (Ù…Ø«Ù„ Render) Ø§Ø¬Ø±Ø§ÛŒ Gunicorn Ø§Ø² $PORT Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    # ØªÙ†Ø¸ÛŒÙ… host='0.0.0.0' Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø­Ù„ÛŒ Ø±ÙˆÛŒ ØªÙ…Ø§Ù… Ø§ÛŒÙ†ØªØ±ÙÛŒØ³â€ŒÙ‡Ø§
    app.run(debug=True, host='0.0.0.0', port=os.environ.get('PORT', 5050))
